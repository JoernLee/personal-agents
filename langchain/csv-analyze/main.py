"""
LangChain å®ç° CSVæ•°æ®åˆ†æåŠ©æ‰‹
"""
import code
from io import StringIO
import os
import re
import sys

from dotenv import load_dotenv
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from langchain_community.chat_models import ChatOpenAI
from langchain_experimental.tools import PythonREPLTool
import pandas as pd

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def setup_qwen_model():
    """è®¾ç½® Qwen3 æ¨¡å‹"""
    # è·å– API å¯†é’¥
    api_key = os.getenv("DASHSCOPE_API_KEY")
    base_url = os.getenv("DASHSCOPE_BASE_URL")
    if not api_key:
        raise ValueError("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
    if not base_url:
        raise ValueError("è¯·è®¾ç½® DASHSCOPE_BASE_URL ç¯å¢ƒå˜é‡")
    
    # åˆå§‹åŒ– ChatOpenAI æ¨¡å‹
    llm = ChatOpenAI(
        openai_api_key=api_key,
        openai_api_base=base_url,
        model_name="qwen-plus",  # å¯ä»¥é€‰æ‹©ä¸åŒçš„ Qwen æ¨¡å‹
        temperature=0.7,
        max_tokens=1024
    )
    
    return llm

def test_pandas():
    """æµ‹è¯• pandas"""
    try:
        # è¯»å–å½“å‰ç›®å½•ä¸‹çš„ Stress_Dataset.csv æ–‡ä»¶
        df = pd.read_csv("./langchain/csv-analyze/Stress_Dataset.csv")
        
        # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        print("CSV æ–‡ä»¶è¯»å–æˆåŠŸ!")
        print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"åˆ—å: {list(df.columns)}")
        print("-" * 50)
        print(f"æ•°æ®ç±»å‹: {df.dtypes}")
        print("-" * 50)
        print(f"æ•°æ®æè¿°: {df.describe()}")
        print("-" * 50)
        print(f"æ•°æ®ç¼ºå¤±å€¼: {df.isnull().sum()}")
        print("-" * 50)
        print("-" * 50)
        print("\nå‰5è¡Œæ•°æ®:")
        print(df.head())
        
    except FileNotFoundError:
        print("é”™è¯¯: æ‰¾ä¸åˆ° Stress_Dataset.csv æ–‡ä»¶")
        return
    except Exception as e:
        print(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return

def test_csv_analyze():
    """æµ‹è¯• CSV æ•°æ®åˆ†æ"""
    llm = setup_qwen_model()

    messages = [
        SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªCSVæ•°æ®åˆ†æåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚"),
        HumanMessage(content="è¯·åˆ†æä¸€ä¸‹ data.csv æ–‡ä»¶çš„ä¸»è¦åŠŸèƒ½ã€‚")
    ];

    # ä½¿ç”¨ pandas è¯»å– CSV æ–‡ä»¶
    df = pd.read_csv("./langchain/csv-analyze/Stress_Dataset.csv")

    # å‡†å¤‡æ•°æ®æ‘˜è¦ä¿¡æ¯
    data_summary = f"""
    æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:
    - æ•°æ®å½¢çŠ¶: {df.shape}
    - åˆ—å: {', '.join(df.columns)}
    - æ•°æ®ç±»å‹: {df.dtypes.to_string()}
    - ç»Ÿè®¡æ‘˜è¦: {df.describe().to_string()}
    - ç¼ºå¤±å€¼: {df.isnull().sum().to_string()}
    """

    messages.append(HumanMessage(content=f"è¿™æ˜¯CSVæ–‡ä»¶çš„æ•°æ®ä¿¡æ¯: {data_summary}"))

    print("Qwen3 æµå¼å›å¤:")
    print("-" * 50) 

    # ä½¿ç”¨æµå¼è¾“å‡º
    try:
        for chunk in llm.stream(messages):
            # æ‰“å°æµå¼è¾“å‡º
            print(chunk.content, end='', flush=True)
    except Exception as e:
        print(f"æµå¼è¾“å‡ºæ—¶å‡ºé”™: {e}")
        # å¦‚æœæµå¼è¾“å‡ºå¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šè¾“å‡º
        response = llm.invoke(messages)
        print(response.content)
        return

def execute_generated_code(code_str, df):
    """å®‰å…¨æ‰§è¡Œç”Ÿæˆçš„Pythonä»£ç """
    try:
        # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„æ‰§è¡Œç¯å¢ƒ
        safe_globals = {
            'pd': pd,
            'df': df,
            'print': print,
            '__builtins__': {
                'len': len,
                'str': str,
                'int': int,
                'float': float,
                'round': round,
                'sum': sum,
                'max': max,
                'min': min,
                'abs': abs,
            }
        }
        
        # æ•è·è¾“å‡º
        old_stdout = sys.stdout
        sys.stdout = captured_output = StringIO()
        
        # æ‰§è¡Œä»£ç 
        exec(code_str, safe_globals)
        
        # æ¢å¤è¾“å‡º
        sys.stdout = old_stdout
        
        # è·å–æ‰§è¡Œç»“æœ
        result = captured_output.getvalue()
        return result.strip() if result else "ä»£ç æ‰§è¡ŒæˆåŠŸï¼Œä½†æ²¡æœ‰è¾“å‡º"
        
    except Exception as e:
        sys.stdout = old_stdout
        return f"ä»£ç æ‰§è¡Œå‡ºé”™: {str(e)}"

def extract_python_code(text):
    """ä»AIå›å¤ä¸­æå–Pythonä»£ç """
    # æŸ¥æ‰¾```python...```ä»£ç å—
    python_pattern = r'```python\s*\n(.*?)\n```'
    matches = re.findall(python_pattern, text, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    # å¦‚æœæ²¡æ‰¾åˆ°ä»£ç å—ï¼ŒæŸ¥æ‰¾```...```
    code_pattern = r'```\s*\n(.*?)\n```'
    matches = re.findall(code_pattern, text, re.DOTALL)
    
    if matches:
        return matches[0].strip()
    
    return text.strip()

def test_complete_workflow():
    """å®Œæ•´çš„å·¥ä½œæµï¼šéœ€æ±‚ â†’ ç”Ÿæˆä»£ç  â†’ æ‰§è¡Œä»£ç  â†’ åˆ†æç»“æœ"""
    llm = setup_qwen_model()
    
    # è¯»å–CSVæ•°æ®
    df = pd.read_csv("./langchain/csv-analyze/Stress_Dataset.csv")
    
    # å‡†å¤‡æ•°æ®æ‘˜è¦
    data_summary = f"""
    æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:
    - æ•°æ®å½¢çŠ¶: {df.shape}
    - åˆ—å: {', '.join(df.columns)}
    - å‰3è¡Œæ•°æ®: {df.head(3).to_string()}
    """
    
    # ç”¨æˆ·éœ€æ±‚
    user_request = "ä½ è§‰å¾—ä»æ•´ä½“æ•°æ®çœ‹ï¼Œä½ æœ‰ä»€ä¹ˆæ•°æ®æ´å¯Ÿå—ï¼Ÿ"
    
    print(f"ğŸ” ç”¨æˆ·éœ€æ±‚: {user_request}")
    print("=" * 60)
    
    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆä»£ç 
    code_gen_prompt = PromptTemplate.from_template(
        """è¯·æ ¹æ®ç”¨æˆ·éœ€è¦ç”Ÿæˆå¯¹åº”çš„ä½¿ç”¨pandaså¤„ç†csvçš„pythonä»£ç ã€‚

        CSVæ•°æ®åŸºæœ¬ä¿¡æ¯: 
        {data_info}

        ç”¨æˆ·éœ€æ±‚: {user_request}

        è¦æ±‚ï¼š
        1. åªè¿”å›å¯æ‰§è¡Œçš„Pythonä»£ç ï¼Œä¸è¦å…¶ä»–è§£é‡Š
        2. ä½¿ç”¨print()è¾“å‡ºç»“æœ
        3. ä»£ç è¦ç®€æ´æ˜äº†
        4. csvè¯»å–è·¯å¾„ï¼š./langchain/csv-analyze/Stress_Dataset.csv

        è¯·ç”Ÿæˆä»£ç ï¼š"""
    )
    
    code_gen_chain = code_gen_prompt | llm
    
    print("ğŸ¤– AIæ­£åœ¨ç”Ÿæˆä»£ç ...")
    ai_response = code_gen_chain.invoke({
        "data_info": data_summary,
        "user_request": user_request
    })
    
    # æå–ä»£ç 
    generated_code = extract_python_code(ai_response.content)
    print("ğŸ“ ç”Ÿæˆçš„ä»£ç :")
    print("-" * 40)
    print(generated_code)
    print("-" * 40)
    
    # ç¬¬äºŒæ­¥ï¼šæ‰§è¡Œä»£ç 
    print("\nâš¡ æ‰§è¡Œä»£ç ä¸­...")
    # åˆ›å»ºPythonæ‰§è¡Œå·¥å…·
    python_repl = PythonREPLTool(globals={"df": df, "pd": pd})
    execution_result = python_repl.run(generated_code)
    print("ğŸ“Š æ‰§è¡Œç»“æœ:")
    print("-" * 40)
    print(execution_result)
    print("-" * 40)
    
    # ç¬¬ä¸‰æ­¥ï¼šAIåˆ†æç»“æœ
    analysis_prompt = PromptTemplate.from_template(
        """è¯·åˆ†æä»¥ä¸‹æ•°æ®åˆ†æç»“æœï¼Œå¹¶ç»™å‡ºç®€æ´çš„ä¸­æ–‡è§£é‡Šï¼š

        ç”¨æˆ·éœ€æ±‚: {user_request}
        æ‰§è¡Œçš„ä»£ç : {code}
        æ‰§è¡Œç»“æœ: {result}

        è¯·ç”¨æ•°æ®åˆ†æå¸ˆçš„è§’åº¦ç”¨3-5å¥è¯è§£é‡Šè¿™ä¸ªç»“æœçš„å«ä¹‰ï¼š"""
    )
    
    analysis_chain = analysis_prompt | llm
    
    print("\nğŸ§  AIæ­£åœ¨åˆ†æç»“æœ...")
    analysis_response = analysis_chain.invoke({
        "user_request": user_request,
        "code": generated_code,
        "result": execution_result
    })
    
    print("ğŸ’¡ ç»“æœåˆ†æ:")
    print("-" * 40)
    print(analysis_response.content)
    print("=" * 60)


if __name__ == "__main__":
    try:
        # test_pandas()
        # test_csv_analyze()
        test_complete_workflow()  # å®Œæ•´å·¥ä½œæµ
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
